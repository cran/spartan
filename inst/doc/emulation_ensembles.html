<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Kieran Alden, Jason Cosgrove" />

<meta name="date" content="2017-09-06" />

<title>Spartan: Expedited and Enriched Analyses Using Emulations &amp; Ensembles</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Spartan: Expedited and Enriched Analyses Using Emulations &amp; Ensembles</h1>
<h4 class="author"><em>Kieran Alden, Jason Cosgrove</em></h4>
<h4 class="date"><em>2017-09-06</em></h4>



<p>This vignette is a short guide on using thew new functionality in Spartan 3 to generate emulations of a simulator from a set of simulation results generated using latin-hypercube sampling, and from those emulations an ensemble. Once this is created, enriched analyses can be performed using Approximate Bayesian Computation and Multi Objective Evolutionary Computation algorithms. This vignette continues the description of the spartan techniques in the sensitivity and netlogo vignettes.</p>
<div id="the-case-study" class="section level3">
<h3>The case study</h3>
<p>Our demonstration utilises data from our previously described agent-based lymphoid tissue development simulator (Patel et al., 2012; Alden et al., 2012). In this system two types of cells migrate into the developing gut and form patches of tissue at varying locations along the gut tract 72 hours later. These mature to form lymphoid organs that trigger an adaptive immune response to gut-based pathogens. Lab experimentation has revealed that cells behave in a different manner (in terms of their velocity and displacement over a 1 hour period) around an initial forming patch than elsewhere in the gut, for reasons not currently understood. To aid our understanding of tissue development, we adopted an agent-based simulation approach. In the example analyses demonstrated here, we are interested in two emergent cell behaviour responses: velocity and displacement, and how these are affected by the values assigned to simulation parameters that capture certain aspects of the biological system. These are captured at simulated hour twelve of tissue development: a time-point where we have experimental data which can be compared to simulation response. The simulator has six parameters for which there is uncertainty in parameter value, each previously described in depth (Alden et al., 2012).</p>
</div>
<div id="prerequisites" class="section level3">
<h3>Prerequisites</h3>
<p>The following are required to run the spartan methods described here:</p>
<ul>
<li>The R statistical environment, version 2.13.1 or later.</li>
<li>The spartan R package, downloaded from CRAN</li>
<li>The neuralnet, randomForest, mlegp, e1071, mco, EasyABC, and ggplot2 R packages, all available for download from CRAN.</li>
<li>Example scripts and datasets are available on the accompanying website (www.york.ac.uk/ycil/software)</li>
</ul>
</div>
<div id="spartan-technique-6-enriching-model-analysis-through-emulation" class="section level2">
<h2>Spartan Technique 6: Enriching Model Analysis Through Emulation</h2>
<p>Using a surrogate tool in place of an original simulator, an emulator, can reduce resource requirements for model analysis and thus enrich understanding of how a model functions and relates back to the problem domain. Such an emulator would take as input a parameter value set and predict the simulation response, e.g. the median simulation response achieved over a high number of replicates. The saving in simulation run time, especially when performing complex sensitivity analyses such as those described in the techniques above, could have a significant impact on a research project. If the accuracy can be quantified and understood, the emulator provides a means of not only performing complex statistical analyses, but may also guide other experiments that could require the original simulation to be reparameterised.</p>
<p>To create an intial dataset for emulator development, use the Latin-Hypercube sampling function described in Technique 3. This dataset should then be partitioned. For any machine learning algorithm it is vital that the dataset being used is partitioned into training, test, and validation sets. This method does below just that. The default split is 75,15,10 respectively, however this can be altered as required. It is also vital for the techniques in this package that the data is normalised such that all data is between 0 and 1. This method also permits data normalisation prior to data partitioning, if normaliseFirst is set to TRUE. Where the parameter data is to be normalised, it is vital that the minimum and maximum values used in sampling for each parameter are provided: this cannot come from the minimum and maximum of the sample as this may not then be representive of the intended parameter space. One object is returned containing training, testing, and validation sets, and the specified minimum and maximum values used in normalisation to ensure normalised predictions generated by an emulator can be rescaled correctly.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read in the dataset. For ease of this tutorial, an exemplar set has been provided in the package,</span>
<span class="kw">data</span>(<span class="st">&quot;sim_data_for_emulation&quot;</span>)
<span class="co"># Simulation parameters</span>
parameters&lt;-<span class="kw">c</span>(<span class="st">&quot;stableBindProbability&quot;</span>,<span class="st">&quot;chemokineExpressionThreshold&quot;</span>,<span class="st">&quot;initialChemokineExpressionValue&quot;</span>,
              <span class="st">&quot;maxChemokineExpressionValue&quot;</span>,<span class="st">&quot;maxProbabilityOfAdhesion&quot;</span>,<span class="st">&quot;adhesionFactorExpressionSlope&quot;</span>)
<span class="co"># Output measures</span>
measures&lt;-<span class="kw">c</span>(<span class="st">&quot;Velocity&quot;</span>,<span class="st">&quot;Displacement&quot;</span>,<span class="st">&quot;PatchArea&quot;</span>)
<span class="co"># Mins and max values used in sampling</span>
sampleMaxes &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">100</span>,<span class="fl">0.9</span>,<span class="fl">0.5</span>,<span class="fl">0.08</span>,<span class="dv">1</span>,<span class="dv">5</span>)
sampleMins &lt;-<span class="kw">cbind</span>(<span class="dv">0</span>,<span class="fl">0.1</span>,<span class="fl">0.1</span>,<span class="fl">0.015</span>,<span class="fl">0.1</span>,<span class="fl">0.25</span>)

## Partition the dataset, in this case normalising the data
partitionedData &lt;-<span class="st"> </span><span class="kw">partition_dataset</span>(sim_data_for_emulation, parameters, <span class="dt">percent_train=</span><span class="dv">75</span>, <span class="dt">percent_test=</span><span class="dv">15</span>, 
    <span class="dt">percent_validation=</span><span class="dv">10</span>, <span class="dt">normalise=</span><span class="ot">TRUE</span>, <span class="dt">sample_mins =</span> sampleMins, <span class="dt">sample_maxes =</span> sampleMaxes)
<span class="co"># If you want to specify a seed to use when randomly paritioning the data, add seed=[desired seed],</span>
<span class="co"># eg seed=10</span></code></pre></div>
<p>The visualise_data_distribution method can be used to provide diagnostic information for the dataset on which the emulators are being trained. A plot is produced that shows any skew in the data, with kurtosis statistics, to indicate any issues this could cause in emulation training. For example a positive skewed dataset may mean that simulation measures on the upper end of the scale may be less well predicted by the emulation techniques included in spartan. The method takes a dataset of a single simulation response as input and produces a graph in the working directory.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">visualise_data_distribution</span>(partitionedData$training,<span class="st">&quot;Velocity&quot;</span>,<span class="st">&quot;Velocity_Diagnostic&quot;</span>)
<span class="co"># If you wish, you can specify the number of bins to use in the plot. A default of 30 is used if not specified</span>
<span class="kw">visualise_data_distribution</span>(partitionedData$training,<span class="st">&quot;Displacement&quot;</span>,<span class="st">&quot;Displacement_Diagnostic&quot;</span>, <span class="dt">num_bins =</span> <span class="dv">10</span>)</code></pre></div>
<p>The training data is then used to aid supervised learning of simulation outputs by a number of machine learning algorithms. Currently spartan includes implementations of a neural network, random forest, support vector machine, general linear model, and gaussian process maps. Once these models have been trained, accuracy of prediction is assessed using the testing and validation subsets. Spartan includes methods to generate output and diagnostic plots to ease assessment of emulation performance.</p>
<p>Firstly, you may need to examine the method emulation_algorithm_settings. Some of the machine learning algorithms incorporated have their own specific settings (neural network and random forest, for example). To keep the methods generic to multiple algorithms and to save passing multiple objects around, these are declared in this function and returned as an algorithmSettings object. Where the user wishes to use the default values, there is no need to run this function: this will be created during emulator generation. However, should the user wish to change any of the settings, such as the number of generations in the neural network or the number of trees in random forest, they should run this method with the new values. In addition, this object will also contain two other settings: whether graphs should be plotted of the accuracy of the emulator against the training and test sets, and whether the emulator object that is created should be stored in the working directory. Parameters this object stores are detailed in the arguments section. However, for neural network emulation, the user is required to initialise this object with a list of neural network hidden layer structures to evaluate (see example). Should this not be done, an error message will be produced and the call will terminate.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set the algorithm settings. Let's say in this case we're generating a neural </span>
<span class="co"># network, so we need to feed in some potential structures to examine</span>
networkStructures&lt;-<span class="kw">list</span>(<span class="kw">c</span>(<span class="dv">4</span>),<span class="kw">c</span>(<span class="dv">3</span>),<span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">3</span>),<span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">3</span>),<span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">4</span>),<span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">3</span>,<span class="dv">3</span>),<span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">3</span>),<span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">3</span>,<span class="dv">2</span>))
<span class="co"># So change the default in the algorithm settings</span>
algorithmSettings&lt;-<span class="kw">emulation_algorithm_settings</span>(<span class="dt">network_structures=</span>networkStructures)</code></pre></div>
<p>The generate_requested_emulations method generates an emulator model from a training set for a specified technique, and generates performance statistics from the test set. The currently implemented techniques are a neural network (using the neuralnet package), a random forest (from the randomforest package), a support vector machine (from package e1071), a gaussian process model (from package mlegp), and a general linear model. Where a neural network is desired, the hyper-parameters are determined using k-fold cross validation from a set of specified network structures. Where a simulation has multiple outputs, an emulator model is created for each output response. This method provides capacity to save the generated emulator models to file, in Rda format, and plot a comparison of the predicted responses to a set of those of the training and test sets, giving correlation of determination (R-squared) and mean squared error values. The method returns a list of emulators of a specified technique, one for each simulation output, and the performance statistics for each measure, including the time taken to generate these emulators. If the training data has been normalised, minimum and maximum sampling values for each parameter are also returned such that any predictions generated using this emulation can be rescaled correctly. If plots are desired (by setting a flag in emulation_algorithm settings), plots produced are stored as PDF’s in the working directory. The same applies to saving the generated emulator, set by the saveEmulation flag in emulation_algorithm_settings. Note that it must be specified as to whether the data being provided in partitionedData has been normalised or not: this affects the output of the plots (as the data is rescaled back to its original scale if the data was normalised). Similarly to the rest of spartan, this method can create emulations for multiple timepoints.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Run the algorithms, here we've given an example for all model types:</span>
glm_fit &lt;-<span class="st"> </span><span class="kw">generate_requested_emulations</span>(<span class="kw">c</span>(<span class="st">&quot;GLM&quot;</span>),partitionedData, parameters,measures, <span class="dt">normalised=</span><span class="ot">TRUE</span>)
svm_fit &lt;-<span class="st"> </span><span class="kw">generate_requested_emulations</span>(<span class="kw">c</span>(<span class="st">&quot;SVM&quot;</span>),partitionedData, parameters,measures, <span class="dt">normalised=</span><span class="ot">TRUE</span>)
rf_fit &lt;-<span class="st"> </span><span class="kw">generate_requested_emulations</span>(<span class="kw">c</span>(<span class="st">&quot;RF&quot;</span>),partitionedData, parameters,measures, <span class="dt">normalised=</span><span class="ot">TRUE</span>)
nn_fit &lt;-<span class="st"> </span><span class="kw">generate_requested_emulations</span>(<span class="kw">c</span>(<span class="st">&quot;NNET&quot;</span>),partitionedData, parameters,measures,algorithmSettings, <span class="dt">normalised=</span><span class="ot">TRUE</span>)
gp_fit &lt;-<span class="st"> </span><span class="kw">generate_requested_emulations</span>(<span class="kw">c</span>(<span class="st">&quot;GP&quot;</span>),partitionedData, parameters,measures, <span class="dt">normalised=</span><span class="ot">TRUE</span>)</code></pre></div>
<p>The generate_predictions_from_emulator method generates predictions on unseen data. This method is called with the emulation object, parameters, meaasures, and unseen data. A flag should also be set as to whether the unseen data, and thus the generated prediction, need to be normalised and rescaled accordingly. Unseen data being input into the emulator must be scaled between 0 and 1, with predictions rescaled after generation. If using the partitioned data object created earlier, the validation set will have already been normalised.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Generate some predictions for unseen data, let's use the validation set</span>
<span class="co"># This has already been normalised:</span>
predictions &lt;-<span class="st"> </span><span class="kw">emulator_predictions</span>(rf_fit, parameters, measures,   partitionedData$validation, <span class="dt">normalise=</span><span class="ot">FALSE</span>, <span class="dt">normalise_result=</span><span class="ot">TRUE</span>)</code></pre></div>
<p>With these emulators generated, Technique 7 can be used to generate combinations of these machine learning algorithms, to generate what is more commonly known as an ensemble model.</p>
</div>
<div id="spartan-technique-7-ensemble-generation" class="section level2">
<h2>Spartan Technique 7: Ensemble Generation</h2>
<p>Technique six detailed the methods through which a series of emulators could be created from a simulation training set. Each emulator development method has the potential to perform very differently for the same dataset. As such, generating a prediction from a combination of emulators, rather than a single emulation alone, may provide an increase in performance. Technique 7 provides a means of creating this combination, an ensemble. This can either be completed from emulators that have been previously developed using Technique 6, or emulations can be created from scratch. In each case, the emulators performance over a dataset is assessed and the emulator weighted, to ensure more accurate emulators are given greater consideration when these are integrated into one ensemble.</p>
<p>This guide will detail the generation of an ensemble from previously generated emulators first, then show how this can be done from scratch in one go.</p>
<p>Where emulations have already been created (see the examples in Technique 6), generate_ensemble_from_existing_emulations combines these to form one ensemble. This takes as input a list of the emulator objects, the simulation parameters and output response labels, and a set of test data from which the performance weights will be evolved. We would recommend providing the testing set of the output from the partition_dataset method of Technique 6. An option is given, by setting these within emulation_algorithm_settings as in Technique 6, to save the ensemble object to file, as well as produce plots showing the accuracy of the generated ensemble for the test data set.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Parameters, measures, partitionedData, and algorithmSettings as declared in Technique 6.</span>
<span class="co"># List of the existing emulations created using Technique 6</span>
existing_simulations &lt;-<span class="st"> </span><span class="kw">list</span>(glm_fit,svm_fit,rf_fit,nn_fit,gp_fit)
<span class="co"># Generate an ensemble from these</span>
<span class="co"># Note the training on the test set, as the original emulators were trained using the partitioned data training set</span>
generated_ensemble &lt;-<span class="st"> </span><span class="kw">generate_ensemble_from_existing_emulations</span>(existing_simulations,parameters, measures, partitionedData$testing,<span class="dt">algorithm_settings=</span>algorithmSettings, <span class="dt">normalise=</span><span class="ot">TRUE</span>, <span class="dt">timepoint=</span><span class="ot">NULL</span>)</code></pre></div>
<p>The method generate_emulators_and_ensemble generates all emulators then combines these into one ensemble. This takes as input a list of the emulation objects to create (could be random forest, support vector machine, neural network, general linear model, and gaussian process model), the simulation parameters and output response labels, an object created by the partitioned_dataset method of Technique 6 (training, testing, and validation datasets), and an object created by method emulation_algorithm_settings. The latter sets key arguments used in emulation creation, and is detailed in Technique 6.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># List of model types to include:</span>
modelList &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;SVM&quot;</span>,<span class="st">&quot;RF&quot;</span>,<span class="st">&quot;GLM&quot;</span>,<span class="st">&quot;NNET&quot;</span>,<span class="st">&quot;GP&quot;</span>)
<span class="co"># Simulation dataset, again using the provided data</span>
<span class="kw">data</span>(<span class="st">&quot;sim_data_for_emulation&quot;</span>)
<span class="co"># Partition the dataset (mins, maxes as declared in Technique 6)</span>
partitionedData &lt;-<span class="st"> </span><span class="kw">partition_dataset</span>(sim_data_for_emulation, parameters, <span class="dt">percent_train=</span><span class="dv">75</span>, <span class="dt">percent_test=</span><span class="dv">15</span>, 
    <span class="dt">percent_validation=</span><span class="dv">10</span>, <span class="dt">normalise=</span><span class="ot">TRUE</span>, <span class="dt">sample_mins =</span> sampleMins, <span class="dt">sample_maxes =</span> sampleMaxes)
<span class="co"># Make the ensemble, specifying that the data above has been normalised. Parameters and measures as declared in Technique 6</span>
<span class="co"># Recall you must have created an algorithmSettings object with the neural network structures to examine</span>
generated_ensemble&lt;-<span class="kw">generate_emulators_and_ensemble</span>(modelList, parameters, measures, partitionedData, 
                                                    <span class="dt">algorithm_settings =</span> algorithmSettings, <span class="dt">normalised=</span><span class="ot">TRUE</span>)</code></pre></div>
<p>With the ensemble generated, a final method is provided to make predictions using the new tool, use_ensemble_to_generate_predictions. Provide this method with the ensemble object, a set of unseen data (parameter values as rows), the simulation parameter and output response labels, and the predicted outputs for that parameter set will be generated. A flag is also set as to whether the unseen data needs to be normalised. Note that any unseen data must be scaled between 0 and 1 for the ensemble to generate a reliable prediction. If using the data partitioning method and using the validation data to make predictions, as below, the data will have already been normalised (so normalise_values is FALSE), yet the predictions should be translated back into their original scale (so normalise_result is TRUE).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># params is a vector of unseen parameter values for which a prediction is being sought.</span>
params&lt;-partitionedData$validation
predictions &lt;-<span class="st"> </span><span class="kw">use_ensemble_to_generate_predictions</span>(generated_ensemble,params,
    parameters,measures,<span class="dt">normalise_values =</span> <span class="ot">FALSE</span>, <span class="dt">normalise_result =</span> <span class="ot">TRUE</span>)</code></pre></div>
</div>
<div id="spartan-technique-8-spartan-analysis-with-ensemble" class="section level2">
<h2>Spartan Technique 8: Spartan Analysis with Ensemble</h2>
<p>Technique 6 detailed how a number of emulators could be constructed that may accurately predict a set of responses of a simulation, with Technique 7 detailing how these were integrated and their performance weighted in order to construct an ensemble. This provides a tool that can be used in place of the original simulation in performing a sensitivity analysis, using the techniques detailed in Techniques 3 and 4. This part of the manual demonstrates how this process could be undertaken, from sampling through running the ensemble and statistical analysis. Note that it is not possible to emulate the results of Technique 2, which require a distribution of results for each parameter set and not a single value prediction.</p>
<p>There are two additional methods that have been added to spartan 3.0 for this process. Both methods returns simulation output predictions in the required format to be analysed by Techniques 3 and 4 of this package.</p>
<p>emulate_lhc_sampled_parameters provides a wrapper to run the ensemble for latin-hypercube generated parameter sets in spartan Technique 3.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">#### The examples below build on those detailed in Techniques 3-4, and 
#### as such that detail is referred to here rather than repeated.

#### Step 1: Use Spartan Technique 3 to generate samples, i.e:
<span class="co">#  Filepath: where the produced parameter sample file should be stored</span>
filepath &lt;-<span class="st"> </span><span class="kw">getwd</span>()
<span class="co"># Declare parameters</span>
parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;stableBindProbability&quot;</span>,<span class="st">&quot;chemokineExpressionThreshold&quot;</span>,
        <span class="st">&quot;initialChemokineExpressionValue&quot;</span>,
        <span class="st">&quot;maxChemokineExpressionValue&quot;</span>,<span class="st">&quot;maxProbabilityOfAdhesion&quot;</span>,
        <span class="st">&quot;adhesionFactorExpressionSlope&quot;</span>)
num_samples &lt;-<span class="st"> </span><span class="dv">500</span>
<span class="co"># Mins and Maxes</span>
pmaxes &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">100</span>,<span class="fl">0.9</span>,<span class="fl">0.5</span>,<span class="fl">0.08</span>,<span class="dv">1</span>,<span class="dv">5</span>)
pmins &lt;-<span class="kw">cbind</span>(<span class="dv">0</span>,<span class="fl">0.1</span>,<span class="fl">0.1</span>,<span class="fl">0.015</span>,<span class="fl">0.1</span>,<span class="fl">0.25</span>)
<span class="co"># Normal or optimal sampling. Recall from Technique 3 that optimal is</span>
<span class="co"># time intensive</span>
algorithm &lt;-<span class="st"> &quot;normal&quot;</span>

<span class="co"># Sampling call</span>
<span class="kw">lhc_generate_lhc_sample</span>(filepath,parameters,num_samples,pmins,pmaxes,
    algorithm)

<span class="co"># However, for the below we do provide an example set of parameters </span>
<span class="co"># as an object that can be loaded in</span>

#### Step 2: Run the wrapper functions detailed above to emulate the 
#### simulation, predicting the output for each parameter set
<span class="co"># Tutorial parameter value sets, constructed using spartan</span>
<span class="kw">data</span>(<span class="st">&quot;emulated_lhc_values&quot;</span>)
<span class="co"># Here we assume that Technique 7 has been used to generate an ensemble,</span>
<span class="co"># and this is read in from file. This will be read into the object</span>
<span class="co"># &quot;built_ensemble&quot;</span>
<span class="co"># We haven't put an exemplar ensemble in the package due to the file size </span>
<span class="co"># of the object, but this can be downloaded from the package website</span>
<span class="co"># However if you're following along from the code above, you could </span>
<span class="co"># instantiate built_ensemble to be generated_ensemble from the previous</span>
<span class="co"># technique</span>
<span class="kw">load</span>(<span class="st">&quot;built_ensemble.Rda&quot;</span>)

<span class="co"># Declare responses:</span>
measures&lt;-<span class="kw">c</span>(<span class="st">&quot;Velocity&quot;</span>,<span class="st">&quot;Displacement&quot;</span>)
measure_scale &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;microns&quot;</span>,<span class="st">&quot;microns/min&quot;</span>)

<span class="co"># Now generate predictions:</span>
<span class="co"># You can do this two ways:</span>
<span class="co"># 1: Provide an object containing all the parameter value sets (i.e. emulated_lhc_values), as below:</span>
<span class="co"># If you have loaded the data from within the package in, use the line below and ignore method 2</span>
<span class="kw">emulate_lhc_sampled_parameters</span>(filepath, built_ensemble, parameters, measures, measure_scale, <span class="dt">dataset =</span> emulated_lhc_values, <span class="dt">normalise =</span> <span class="ot">TRUE</span>)
<span class="co"># 2: Or, if you have generated a CSV file with all the values, give the name of that file (should be in the specified filepath)</span>
parameterFileName &lt;-<span class="st"> &quot;LHC_Parameters_for_Runs.csv&quot;</span>
<span class="kw">emulate_lhc_sampled_parameters</span>(filepath, ensemble, parameters, measures, measure_scale, <span class="dt">param_file =</span> parameterFileName)

<span class="co"># The above will calculate all partial rank correlation coefficiejnts and graph the results into the present working directory</span>

<span class="co"># If you wanted, you could do an lhc for a single emulation object, not just an ensemble. </span>
<span class="co"># If you wanted to do that, say for the neural network object nn_fit created in previous steps in this vignette, you would do:</span>
<span class="kw">emulate_lhc_sampled_parameters</span>(filepath, nn_fit, parameters, measures, measure_scale, <span class="dt">dataset =</span> emulated_lhc_values, 
                               <span class="dt">ensemble_set =</span> <span class="ot">FALSE</span>, <span class="dt">normalise =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>emulate_efast_sampled_parameters provides a wrapper to run the ensemble for parameter sets generated for performing the extended fourier amplitude sampling test, spartan Technique 4.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Number of curves for eFAST</span>
numCurves &lt;-<span class="st"> </span><span class="dv">3</span>
<span class="co"># Number of samples to take from each curve</span>
numSamples &lt;-<span class="st"> </span><span class="dv">65</span>
<span class="co"># Where samples are stored</span>
filepath &lt;-<span class="st"> </span><span class="kw">getwd</span>()
<span class="co"># Recall we need to add a dummy parameter for statistical comparison</span>
parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;stableBindProbability&quot;</span>,<span class="st">&quot;chemokineExpressionThreshold&quot;</span>,
        <span class="st">&quot;initialChemokineExpressionValue&quot;</span>,
        <span class="st">&quot;maxChemokineExpressionValue&quot;</span>,<span class="st">&quot;maxProbabilityOfAdhesion&quot;</span>,
        <span class="st">&quot;adhesionFactorExpressionSlope&quot;</span>, <span class="st">&quot;dummy&quot;</span>)
<span class="co"># Max of all parameters. Include a max value for dummy (1 here)</span>
pmax &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">100</span>,<span class="fl">0.9</span>,<span class="fl">0.5</span>,<span class="fl">0.08</span>,<span class="dv">1</span>,<span class="dv">5</span>,<span class="dv">1</span>)
<span class="co"># Min of all parameters. Include a min value for dummy (0 here)</span>
pmin &lt;-<span class="kw">cbind</span>(<span class="dv">0</span>,<span class="fl">0.1</span>,<span class="fl">0.1</span>,<span class="fl">0.015</span>,<span class="fl">0.1</span>,<span class="fl">0.25</span>,<span class="dv">0</span>)

#### Step 1: Use Spartan Technique 4 to generate samples
<span class="kw">efast_generate_sample</span>(filepath, numCurves,numSamples,parameters, pmin, pmax)
<span class="co"># As this method produces several CSV files (one per parameter/curve), and it is these files which are </span>
<span class="co"># read in to make the predictions, these have not been included as an object that can be loaded in. </span>
<span class="co"># However an example set is available on the project website. Extract that into the working folder and then run the below.</span>

<span class="co"># Make predictions and plot the results</span>
<span class="kw">emulate_efast_sampled_parameters</span>(filepath, built_ensemble, parameters, measures, numCurves, <span class="dt">normalise =</span> <span class="ot">TRUE</span>)

<span class="co"># Analyse:</span>
<span class="kw">efast_run_Analysis</span>(filepath,measures,parameters,numCurves, numSamples,<span class="dv">1</span>:<span class="dv">2</span>,<span class="fl">0.95</span>,<span class="ot">TRUE</span>,<span class="st">&quot;eFAST_Analysis.csv&quot;</span>)

<span class="co"># If you wanted to use a single emulator rather than the ensemble, say nn_fit created earlier, you would do:</span>
<span class="kw">emulate_efast_sampled_parameters</span>(filepath, nn_fit, parameters, measures, numCurves, <span class="dt">normalise =</span> <span class="ot">TRUE</span>, <span class="dt">ensemble_set =</span> <span class="ot">FALSE</span>)</code></pre></div>
</div>
<div id="spartan-technique-9-using-ensemble-for-approximate-bayesian-computation-with-easyabc" class="section level2">
<h2>Spartan Technique 9: Using Ensemble for Approximate Bayesian Computation with EasyABC</h2>
<p>The ensemble model created using Technique 7 enables the performance of complex statistical analyses that could not be performed on more intensive simulations being emulated. The application of Approximate Bayesian Computation, to deduce the posterior distribution of the parameters, is one such technique, and one that could provide an increased understanding of simulation behaviour. The EasyABC package in R permits the performance of ABC techniques, and is well supported and documented. In running any of the numerous techniques in EasyABC, one has to provide a model, in which generated parameter value sets are processed and output responses generated. In order to make the ensemble models produced by spartan compatible with EasyABC, we have provided a wrapper which acts as the model input to the EasyABC call, which in turn produces predictions using the ensemble, normalising the EasyABC generated parameter set first if need be then rescaling the predictions to their original scale (recall the ensemble must take data scaled between 0 and 1).</p>
<p>The EasyABC model function, that utilises the wrapper detailed here to run the ensemble, can only take one parameter input: the parameter values. This is problematic as to generate a prediction for those values, we must provide the names of the simulation parameters and measures, the built ensemble, and whether or not the parameter set and responses have been normalised. To get around that problem, this method creates an object in the working directory that contains these values, and the ensemble abc wrapper provided in spartan can then read these in. Thus, this method MUST be run before using the EasyABC package with the ensemble:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Four examples here of applying an ensemble to perform the  sequential ABC methods in EasyABC
<span class="co"># Firstly make sure the parameters and measures are declared</span>
parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;stableBindProbability&quot;</span>,<span class="st">&quot;chemokineExpressionThreshold&quot;</span>,
    <span class="st">&quot;initialChemokineExpressionValue&quot;</span>,<span class="st">&quot;maxChemokineExpressionValue&quot;</span>,
    <span class="st">&quot;maxProbabilityOfAdhesion&quot;</span>,<span class="st">&quot;adhesionFactorExpressionSlope&quot;</span>)
measures&lt;-<span class="kw">c</span>(<span class="st">&quot;Velocity&quot;</span>,<span class="st">&quot;Displacement&quot;</span>)
<span class="co"># Load in an ensemble generated in Technique 7, this loads in as built_ensemble</span>
<span class="kw">load</span>(<span class="st">&quot;built_ensemble_12.Rda&quot;</span>)
<span class="co"># Whether the parameter sets generated by the ABC algorithm should be normalised </span>
<span class="co"># for input into the ensemble</span>
normalise_values =<span class="st"> </span><span class="ot">TRUE</span>
<span class="co"># Whether the predictions for the parameter set should be normalised</span>
normalise_result =<span class="st"> </span><span class="ot">TRUE</span>

<span class="co"># Establish the priors for each parameter</span>
prior=<span class="kw">list</span>(<span class="kw">c</span>(<span class="st">&quot;unif&quot;</span>,<span class="dv">0</span>,<span class="dv">100</span>),<span class="kw">c</span>(<span class="st">&quot;unif&quot;</span>,<span class="fl">0.1</span>,<span class="fl">0.9</span>),<span class="kw">c</span>(<span class="st">&quot;unif&quot;</span>,<span class="fl">0.1</span>,<span class="fl">0.5</span>),
    <span class="kw">c</span>(<span class="st">&quot;unif&quot;</span>,<span class="fl">0.015</span>,<span class="fl">0.08</span>),<span class="kw">c</span>(<span class="st">&quot;unif&quot;</span>,<span class="fl">0.1</span>,<span class="fl">1.0</span>),<span class="kw">c</span>(<span class="st">&quot;unif&quot;</span>,<span class="fl">0.25</span>,<span class="fl">5.0</span>))


<span class="co"># Summary statistics to be targetted</span>
sum_stat_obs=<span class="kw">c</span>(<span class="fl">4.4677342593</span>,<span class="fl">28.5051144444</span>)

<span class="co"># Create the file that will be read in by the wrapper:</span>
<span class="kw">create_abc_settings_object</span>(parameters, measures, built_ensemble, normalise_values, 
                           normalise_result)</code></pre></div>
<p>The ensemble_abc_wrapper then provides a means of running the ensemble within the EasyABC methods. This method should be stated as the “model” argument of EasyABC methods such as ABC_sequential. Should the method above not have been run first, an error message will be produced. Here are a variety of examples of performing ABC analysis using the wrapper.</p>
<p>Finally, graph_Posteriors_All_Parameters provides a means of plotting the produced posterior distribution for all parameters for which the value is being explored.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Beaumont method using spartan ensemble wrapper</span>
<span class="kw">library</span>(EasyABC)
numRunsUnderThreshold=<span class="dv">100</span>
tolerance=<span class="kw">c</span>(<span class="dv">20</span>,<span class="dv">15</span>,<span class="fl">10.00</span>,<span class="dv">7</span>,<span class="fl">5.00</span>)
abc_resultSet&lt;-<span class="kw">ABC_sequential</span>(<span class="dt">method=</span><span class="st">&quot;Beaumont&quot;</span>,
    <span class="dt">model=</span>ensemble_abc_wrapper, <span class="dt">prior=</span>prior, 
    <span class="dt">nb_simul=</span>numRunsUnderThreshold, 
    <span class="dt">summary_stat_target=</span>sum_stat_obs,
    <span class="dt">tolerance_tab=</span>tolerance, <span class="dt">verbose=</span><span class="ot">TRUE</span>)

<span class="co"># Graph the result</span>
<span class="co"># Ranges:</span>
sampleMins &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.1</span>,<span class="fl">0.1</span>,<span class="fl">0.015</span>,<span class="fl">0.1</span>,<span class="fl">0.25</span>)
sampleMaxes&lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">100</span>,<span class="fl">0.9</span>,<span class="fl">0.5</span>,<span class="fl">0.015</span>,<span class="fl">0.08</span>,<span class="fl">1.0</span>,<span class="fl">5.0</span>)
<span class="kw">graph_Posteriors_All_Parameters</span>(abc_resultSet,
    parameters, sampleMins, sampleMaxes)


<span class="co"># Delmoral method using spartan ensemble wrapper</span>
initialSims=<span class="dv">500</span>
decreaseSampleSizeEachStep &lt;-<span class="st"> </span><span class="fl">0.5</span>
numberSimsPerformedPerParticle &lt;-<span class="st"> </span><span class="dv">1</span>
minSampleSizeForResampling &lt;-<span class="st"> </span>initialSims/<span class="dv">2</span> 
finalToleranceLevel &lt;-<span class="st"> </span><span class="fl">0.05</span>

abc_resultSet&lt;-<span class="kw">ABC_sequential</span>(<span class="dt">method=</span><span class="st">&quot;Delmoral&quot;</span>, 
    <span class="dt">model=</span>ensemble_abc_wrapper, <span class="dt">prior=</span>prior, <span class="dt">nb_simul=</span>initialSims, 
    <span class="dt">summary_stat_target=</span>sum_stat_obs, 
    <span class="dt">alpha=</span>decreaseSampleSizeEachStep, 
    <span class="dt">tolerance_target=</span>finalToleranceLevel, 
    <span class="dt">M=</span>numberSimsPerformedPerParticle, 
    <span class="dt">nb_threshold=</span>minSampleSizeForResampling, 
    <span class="dt">verbose=</span><span class="ot">TRUE</span>)

<span class="co"># Graph the result</span>
<span class="kw">graph_Posteriors_All_Parameters</span>(abc_resultSet,
    parameters, sampleMins, sampleMaxes)


<span class="co"># Drovandi method:</span>
initialSims=<span class="dv">500</span>
finalToleranceLevel =<span class="st"> </span><span class="fl">0.05</span>
proportionBestFitToUpdate=<span class="fl">0.7</span> 
targetProportionUnovedParticles=<span class="fl">0.01</span> 
abc_resultSet&lt;-<span class="kw">ABC_sequential</span>(<span class="dt">method=</span><span class="st">&quot;Drovandi&quot;</span>, 
    <span class="dt">model=</span>ensemble_abc_wrapper,<span class="dt">prior=</span>prior, 
    <span class="dt">summary_stat_target=</span>sum_stat_obs, 
    <span class="dt">alpha =</span> proportionBestFitToUpdate, 
    <span class="dt">c=</span>targetProportionUnovedParticles, 
    <span class="dt">nb_simul =</span> initialSims, 
    <span class="dt">tolerance=</span>finalToleranceLevel, 
    <span class="dt">verbose=</span><span class="ot">TRUE</span>)

<span class="co"># Graph the result</span>
<span class="kw">graph_Posteriors_All_Parameters</span>(abc_resultSet,
    parameters, sampleMins, sampleMaxes)</code></pre></div>
</div>
<div id="spartan-technique-10-optimising-emulator-outputs-with-nsga2" class="section level2">
<h2>Spartan Technique 10: Optimising Emulator Outputs with NSGA2</h2>
<p>To determine emulator inputs that correspond to a desired output configuration we use the non-dominated sorting genetic algorithm II (nsgaII), a multiobjective genetic algorithm. In this scheme a solution is called nondominated, Pareto optimal, Pareto efficient or noninferior, if none of the objective functions can be improved in value without degrading some of the other objective values.</p>
<p>If the Pareto front comprises more members than the population size, a subset composed of those Pareto members having the largest fitness differences between their immediate neighbours summed for all objectives is selected. If the Pareto front comprises fewer members than the population size then members of the next front (those dominated by only one other solution) are selected in the same manner, and so on until the entire population has been selected. New solutions are generated through crossover of parents with mutation. Each candidate solution is assessed by a user defined fitness function, which nsga2 seeks to minimise</p>
<p>There are four methods to this process:</p>
<p>nsga2_set_user_params: Creates an object of the analysis parameters that will be used to evolve parameter sets or screen parameters for NSGA-2. The user should ensure this is called first, establishing this object such that it can be passed in to the relevant method.</p>
<p>set.nsga_sensitivity_params: Establish the parameters for the NSGA-2 sensitivity analysis, creating an object that is used within the method that screens NSGA-2 parameters.</p>
<p>screen_nsga2_parameters: This method performs a sensitvity analysis of key settings for the nsga2 algorithm. Different values of generation number, crossover and mutation rate are assessed and the values for each objective, along with the variance of the parameter inputs are written out to file in .csv format so the user can assess which settings are best suited to the chosen application. Values for the crossover and mutation distribution indices,used in simulated binary crossover are left at their default settings, but can be overwritten when running the emulator_parameter_evolution method.</p>
<p>emulator_parameter_evolution: This method takes a user specified fitness function and runs the nsga2 algorithm on an emulator using the nsga2 implementation provided in the mco package. The method requires the user to input parameter and algorithm settings as shown in the example below. The method outputs a list describing the final population in terms of the input parameters (par), the values for each objective (res), an evolved set of parameter inputs (par), and a boolean stating whether the candidate is pareto optimal (pareto.optimal)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Declare a fitness function in a R script. Fitness function below can be downloaded from the website</span>
fitness_function &lt;-<span class="st"> &quot;eval_function.R&quot;</span>
<span class="co"># Read in the fitness function</span>
<span class="kw">source</span>(fitness_function)
<span class="co"># Load a ensemble generated by Technique 7</span>
<span class="kw">load</span>(<span class="st">&quot;built_ensemble.Rda&quot;</span>)
<span class="co"># The target values for objectives that the ngsa2 should try to produce using the emulator (minimising the error between prediction and these observed values).</span>
desiredResponses &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">4.3</span>,<span class="dv">24</span>)
<span class="co"># Measures, parameters, sampleMins, sampleMaxes as those declared previously above</span>
<span class="co"># Set the parameters and settings</span>
sensitivtyParams &lt;-<span class="st"> </span><span class="kw">set.nsga_sensitivity_params</span>(<span class="dt">generation_min=</span><span class="dv">100</span>, <span class="dt">crossover_min=</span><span class="fl">0.1</span>,<span class="dt">mutation_min=</span><span class="fl">0.1</span>, 
                                                <span class="dt">generation_max=</span><span class="dv">500</span>,<span class="dt">crossover_max=</span><span class="fl">1.0</span>, <span class="dt">mutation_max=</span><span class="fl">1.0</span>, <span class="dt">seed=</span><span class="dv">500</span>)

nsga2_params &lt;-<span class="st"> </span><span class="kw">nsga2_set_user_params</span>(built_ensemble, parameters, measures, desiredResponses, sampleMins, sampleMaxes)

nsga2_settings &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="st">&quot;popsize&quot;</span>=<span class="dv">100</span>,<span class="st">&quot;generations&quot;</span> =<span class="st"> </span><span class="dv">100</span>, <span class="st">&quot;cprob&quot;</span> =<span class="st"> </span><span class="fl">0.3</span>, <span class="st">&quot;mprob&quot;</span> =<span class="st"> </span><span class="fl">0.1</span>)

<span class="co"># Screen the parameters using nsga2</span>
parameter_sensitivities &lt;-<span class="st"> </span><span class="kw">screen_nsga2_parameters</span>(evalfunction, nsga2_params, sensitivityParams, nsga2_settings)

<span class="co"># Evolve parameters</span>
<span class="kw">emulator_parameter_evolution</span>(fitness_function, nsga2_params, nsga2_settings)</code></pre></div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
